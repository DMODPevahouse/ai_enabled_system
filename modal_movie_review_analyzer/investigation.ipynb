{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36578ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5889bdd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_720/3058834800.py:1: DtypeWarning: Columns (18,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"amazon_movie_reviews.csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"amazon_movie_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a44fafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 26 columns):\n",
      " #   Column             Non-Null Count    Dtype  \n",
      "---  ------             --------------    -----  \n",
      " 0   Unnamed: 0         1000000 non-null  int64  \n",
      " 1   rating             1000000 non-null  float64\n",
      " 2   review_title       999930 non-null   object \n",
      " 3   text               999922 non-null   object \n",
      " 4   images_x           1000000 non-null  object \n",
      " 5   asin               1000000 non-null  object \n",
      " 6   parent_asin        1000000 non-null  object \n",
      " 7   user_id            1000000 non-null  object \n",
      " 8   timestamp          1000000 non-null  int64  \n",
      " 9   helpful_vote       1000000 non-null  int64  \n",
      " 10  verified_purchase  1000000 non-null  bool   \n",
      " 11  main_category      990649 non-null   object \n",
      " 12  movie_title        457708 non-null   object \n",
      " 13  subtitle           20116 non-null    object \n",
      " 14  average_rating     999990 non-null   float64\n",
      " 15  rating_number      999990 non-null   float64\n",
      " 16  features           457710 non-null   object \n",
      " 17  description        457710 non-null   object \n",
      " 18  price              388749 non-null   object \n",
      " 19  images_y           1000000 non-null  object \n",
      " 20  videos             1000000 non-null  object \n",
      " 21  store              389852 non-null   object \n",
      " 22  categories         457710 non-null   object \n",
      " 23  details            1000000 non-null  object \n",
      " 24  bought_together    0 non-null        float64\n",
      " 25  author             118 non-null      object \n",
      "dtypes: bool(1), float64(4), int64(3), object(18)\n",
      "memory usage: 191.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eed1e9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    1,    4,    7,    2,    3,    6,   15,   14,   10,    9,\n",
       "          5,   34,    8,   18,   17,   21,   39,   11,   12,  293,   22,\n",
       "         23,   83,   35,  126,  192,   62,   64,   27,   19,   20,   32,\n",
       "         13,   66,  255,   99,   55,  234,   41,  119,   97,   44,   79,\n",
       "         29,   16,  191,   47,   24,   57,   84,   31,   48,   77,   91,\n",
       "         25,   36, 1450,   26,   30,  103,   70,   51,   93,   28,   37,\n",
       "         38,  117,   67,   43,   46,  246,   68,  136,  260,   40,   73,\n",
       "        115,   60,   33,   59,   71,   45,   61,  141,  105,   92,  225,\n",
       "         72,  247,   85,   94,   75,   80,   42,   81,   53,   49,   50,\n",
       "        108,   69,   56,  163,   54,   52,  172,  166,  173,  155,  201,\n",
       "        132,  128,  218,  157,  100,  107,  113,  112,  280,   87,  297,\n",
       "        151,  196,  148,  116,   74,   82,  106,   78,   58,  109,  759,\n",
       "        239,  364,  204,  120,  162,   96,  167,  182,  194,  305,  122,\n",
       "         76,   95,   63,  139,  138,  127,   65,   88,  433,  144,  188,\n",
       "        121,  114,  118,  197,  178,  279,  150, 1370,  771,   90,  131,\n",
       "        129,  484,  134,  176,  694,  102,  152,  164,  156,  304,  241,\n",
       "        171,  133,  170,  258,  124,  153,  146,  160,   98,  154,  175,\n",
       "        214,  392,  140,  444,  195, 2050,  190,  336,  650,  217,  193,\n",
       "        125,  236,  111,  110,  104,  200,  228,  451,  372,  460,  383,\n",
       "        617,  231,  232,  748,  174,  321,  135,  339,  211,  380,  322,\n",
       "        316, 1183,  222,  276,  284,  282,  202,  142,   86,  263,  348,\n",
       "        754,  353,  206,  165,  327,  208,  147,  207,  216,  458,  130,\n",
       "        248,  262,  357,  299,  233, 1666,  177,  459,   89,  101,  203,\n",
       "        169, 1239,  281,  261,  145,  301,  235,  272,  183,  210,  506,\n",
       "       2162,  123,  698,  158,  267,  187,  161,  515, 1493,  159,  496,\n",
       "        317,  340,  259,  220,  184,  189,  376,  368,  209,  358,  223,\n",
       "        212,  221,  395,  273,  397, 1465,  253,  313,  181,  198,  597,\n",
       "        640,  453,  420,  329,  330,  252,  143,  842,  277,  406,  251,\n",
       "        492,  628,  727,  286,  296,  409,  275,  704, 1477,  319,  186,\n",
       "        685,  411,  237,  199,  227,  254,  213,  180,  605,  185,  137,\n",
       "        363,  266,  373,  556,  245,  257,  250,  332,  386,  243,  270,\n",
       "        168,  343,  238,  226, 1317, 1014,  337,  347,  419,  149,  285,\n",
       "        387,  437,  249, 1074,  378, 1478,  697,  413,  264,  215,  333,\n",
       "        592,  289,  436,  667,  544,  678,  382,  278,  414,  630,  303,\n",
       "        600, 1328,  421,  205,  295,  488,  648,  366,  381,  349,  346,\n",
       "        764,  287,  396,  242,  910,  324,  457,  761,  314,  615,  230,\n",
       "        782,  335,  469,  325,  224,  783,  893,  240,  384,  497,  621,\n",
       "       1347, 1312,  540])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"helpful_vote\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85c83ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 2087647), ('and', 1295293), ('a', 1154012), ('to', 1019354), ('of', 991948), ('I', 834254), ('is', 765440), ('in', 570074), ('it', 522050), ('this', 521103), ('was', 436773), ('that', 411249), ('for', 385598), ('with', 331360), ('but', 311052), ('as', 301226), ('movie', 297938), ('The', 268482), ('on', 260803), ('you', 241045), ('/><br', 231728), ('are', 230478), ('not', 228072), ('have', 224230), ('be', 178366), ('so', 158739), ('like', 158161), ('all', 155878), ('good', 155487), ('one', 154734), ('my', 154385), ('This', 152811), ('his', 149237), ('an', 142232), ('at', 139760), ('they', 139281), ('from', 134365), ('great', 130851), ('just', 130428), ('It', 123965), ('very', 122119), ('by', 121389), ('about', 118933), ('he', 116405), ('who', 115169), ('has', 113687), ('more', 113562), ('or', 111216), ('love', 108254), ('her', 105215), ('some', 102253), ('would', 102008), ('film', 101403), ('really', 100849), ('story', 98231), ('watch', 95606), ('what', 94900), ('movie.', 94058), ('will', 93598), ('out', 92610), ('had', 89645), ('Great', 89249), ('were', 84668), ('when', 84042), ('if', 83361), ('up', 82386), ('it.', 81753), ('can', 81122), ('see', 80026), ('their', 78852), ('get', 77169), ('much', 74830), ('show', 74313), ('than', 74118), ('time', 70330), ('she', 69724), ('there', 69564), ('first', 69111), ('me', 68454), (\"it's\", 67737), ('we', 67179), ('been', 66422), ('how', 66013), ('only', 64325), ('-', 64196), ('well', 64109), ('no', 64102), ('even', 63841), ('A', 63819), ('into', 63394), ('which', 62946), ('because', 59769), ('series', 59509), ('do', 59208), ('other', 57459), ('little', 56046), ('watching', 55354), ('your', 55000), ('movies', 54013), ('could', 52407)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Assuming df is your DataFrame and 'reviews' is the column containing the word reviews\n",
    "reviews = df['text']\n",
    "\n",
    "\n",
    "# Convert all the values in the 'reviews' column to strings\n",
    "reviews = reviews.astype(str)\n",
    "# Join all the reviews into a single string\n",
    "all_reviews = ' '.join(reviews)\n",
    "\n",
    "# Use Counter to count the frequency of each word\n",
    "word_counts = Counter(all_reviews.split())\n",
    "\n",
    "# The 'most_common()' method of Counter can be used to get the most common words\n",
    "# For example, to get the top 10 most common words:\n",
    "most_common_words = word_counts.most_common(100)\n",
    "\n",
    "print(most_common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1ea9fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57b0d539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Download the stopwords corpus if it is not already downloaded\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Assuming df is your DataFrame and 'reviews' is the column containing the word reviews\n",
    "reviews = df['text']\n",
    "\n",
    "# Convert all the values in the 'reviews' column to strings\n",
    "reviews = reviews.astype(str)\n",
    "\n",
    "# Join all the reviews into a single string\n",
    "all_reviews = ' '.join(reviews)\n",
    "\n",
    "# Use Counter to count the frequency of each word\n",
    "word_counts = Counter(all_reviews.split())\n",
    "\n",
    "# Get a list of common English words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Filter out common words from your word counts\n",
    "filtered_word_counts = {word: count for word, count in word_counts.items() if word.lower() not in stop_words}\n",
    "\n",
    "# Convert the filtered word counts back to a Counter object\n",
    "filtered_word_counts = Counter(filtered_word_counts)\n",
    "\n",
    "# The 'most_common()' method of Counter can be used to get the most common words\n",
    "# For example, to get the top 10 most common words:\n",
    "most_common_words = filtered_word_counts.most_common(30)\n",
    "\n",
    "# Extract the words and their counts\n",
    "words, counts = zip(*most_common_words)\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "# Plot the words and their counts\n",
    "plt.bar(words, counts)\n",
    "plt.title('Top Words in Reviews')\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dc2f18c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\'Inventor Flint Lockwood thought he saved the world when he destroyed his most infamous invention  a machine that turned water into food causing cheeseburger rain and spaghetti tornadoes. But Flint soon learns that his invention survived and is now combining food and animals to create \"foodimals!\" Flint and his friends embark on an adventurously mouth-watering mission to battle hungry tacodiles, shrimpanzees, hippotatomuses, cheesepiders and other foodimals to save the world  again!\\']'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"description\"][43563]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3374c46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df is your DataFrame and \"column_name\" is the name of the column\n",
    "column_name = \"videos\"\n",
    "\n",
    "# Replace empty strings with NaN\n",
    "df[column_name] = df[column_name].replace('', np.nan)\n",
    "\n",
    "# Drop rows with NaN values in the specified column\n",
    "df = df.dropna(subset=[column_name])\n",
    "\n",
    "# Drop rows with empty lists in the specified column\n",
    "if df[column_name].apply(lambda x: isinstance(x, list) and len(x) == 0).any():\n",
    "    # If so, drop rows with empty lists\n",
    "    df = df[df[column_name] != []].dropna(subset=[column_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1f2b2a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Series name: videos\n",
      "Non-Null Count    Dtype \n",
      "--------------    ----- \n",
      "1000000 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 7.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df[column_name].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aa24283d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from data_pipeline import ETL_Pipeline, preprocess, encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ff433112",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_720/3904227517.py:1: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"small_movie_reviews.csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"small_movie_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "48239fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a4feaf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the corpus\n",
    "vocab, tokens = preprocess(df[\"text\"])\n",
    "\n",
    "# Encode the preprocessed tokens using the specified encoding method\n",
    "encoding_method = 'Bag-of-Words'\n",
    "encoded_tokens = encode(tokens, encoding_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "330f9842",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_method = 'TF-IDF'\n",
    "encoded_tokens = encode(tokens, encoding_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a0d045c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_method = 'Word2Vec'\n",
    "encoded_tokens = encode(tokens, encoding_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "195156cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "etl = ETL_Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "829f23b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "etl.data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4be07d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "etl.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "6fba63d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "etl.load(\"testing_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a433341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"testing_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "75713620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 80752 entries, 0 to 80751\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   rating          80752 non-null  float64\n",
      " 1   review_title    80742 non-null  object \n",
      " 2   text            80745 non-null  object \n",
      " 3   helpful_vote    80752 non-null  int64  \n",
      " 4   main_category   80001 non-null  object \n",
      " 5   average_rating  80751 non-null  float64\n",
      " 6   rating_number   80751 non-null  float64\n",
      "dtypes: float64(3), int64(1), object(3)\n",
      "memory usage: 4.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dcce14f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].fillna(\"\")\n",
    "vocab, tokens = preprocess(df[\"text\"])\n",
    "encoding_method = 'Word2Vec'\n",
    "encoded_tokens = encode(tokens, encoding_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5a6dcf0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    text url httpswwwexamplecom punctuation\n",
      "Name: clean_text, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Define a custom preprocessing function\n",
    "def custom_preprocessing(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'https?://\\S+', '', text)\n",
    "    \n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
    "    \n",
    "    # Lemmatize tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    # Join tokens back into a string\n",
    "    text = ' '.join(tokens)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Define a function to preprocess text data\n",
    "def preprocess_text_data(data: pd.Series) -> pd.Series:\n",
    "    return data.apply(custom_preprocessing)\n",
    "\n",
    "# Apply the function to preprocess the text data\n",
    "df_test = pd.DataFrame({'text': ['This is a text with some urls: https://www.example.com and some punctuations!?!']})\n",
    "df_test['clean_text'] = preprocess_text_data(df_test['text'])\n",
    "\n",
    "print(df_test['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "eba2e5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a text with some urls: https://www.exa...</td>\n",
       "      <td>text url httpswwwexamplecom punctuation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  This is a text with some urls: https://www.exa...   \n",
       "\n",
       "                                clean_text  \n",
       "0  text url httpswwwexamplecom punctuation  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "73033861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0\n",
      "0  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:808: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "def encode_text_data(data: pd.Series) -> pd.DataFrame:\n",
    "    # Initialize a LabelEncoder object\n",
    "    le = LabelEncoder()\n",
    "    # Fit and transform the column data\n",
    "    encoded_data = le.fit_transform(data)\n",
    "\n",
    "    # Initialize a OneHotEncoder object with sparse output\n",
    "    ohe = OneHotEncoder(sparse=True)\n",
    "    # Fit and transform the encoded data\n",
    "    encoded_data = ohe.fit_transform(encoded_data.reshape(-1, 1))\n",
    "\n",
    "    # Create a new DataFrame with the encoded data\n",
    "    encoded_df = pd.DataFrame.sparse.from_spmatrix(encoded_data)\n",
    "\n",
    "    return encoded_df\n",
    "encoded_df = encode_text_data(df_test[\"clean_text\"])\n",
    "\n",
    "print(encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "722b2259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def custom_preprocessing(text):\n",
    "    # Check for empty strings or NaN values\n",
    "    if pd.isna(text) or text == '':\n",
    "        return ''\n",
    "\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'https?://\\S+', '', text)\n",
    "    \n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
    "    \n",
    "    # Lemmatize tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    # Join tokens back into a string\n",
    "    text = ' '.join(tokens)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "cf5bf2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         amazon please buy show im hooked\n",
       "1                                      love movie hit feel\n",
       "2                                    good movie liked seen\n",
       "3        one classic one friend watch many time good ac...\n",
       "4             gift picked friend kid enjoy much time watch\n",
       "                               ...                        \n",
       "80747                      great series nice collector box\n",
       "80748                                        awesome movie\n",
       "80749    testing amazon prime video player really tryin...\n",
       "80750    buy worth money entertaining worth adding lotr...\n",
       "80751    one favorite christmas movie everyone see movi...\n",
       "Name: clean_text, Length: 80752, dtype: object"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "39f207b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:808: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "encoded_df = encode_text_data(df[\"clean_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "99410fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>604695</th>\n",
       "      <th>604696</th>\n",
       "      <th>604697</th>\n",
       "      <th>604698</th>\n",
       "      <th>604699</th>\n",
       "      <th>604700</th>\n",
       "      <th>604701</th>\n",
       "      <th>604702</th>\n",
       "      <th>604703</th>\n",
       "      <th>604704</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809802</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809803</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809804</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809805</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809806</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>809807 rows  604705 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1       2       3       4       5       6       7       \\\n",
       "0          0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1          0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2          0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3          0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4          0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "809802     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "809803     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "809804     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "809805     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "809806     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "        8       9       ...  604695  604696  604697  604698  604699  604700  \\\n",
       "0          0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1          0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2          0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3          0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4          0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...        ...     ...  ...     ...     ...     ...     ...     ...     ...   \n",
       "809802     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "809803     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "809804     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "809805     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "809806     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "        604701  604702  604703  604704  \n",
       "0          0.0     0.0     0.0     0.0  \n",
       "1          0.0     0.0     0.0     0.0  \n",
       "2          0.0     0.0     0.0     0.0  \n",
       "3          0.0     0.0     0.0     0.0  \n",
       "4          0.0     0.0     0.0     0.0  \n",
       "...        ...     ...     ...     ...  \n",
       "809802     0.0     0.0     0.0     0.0  \n",
       "809803     0.0     0.0     0.0     0.0  \n",
       "809804     0.0     0.0     0.0     0.0  \n",
       "809805     0.0     0.0     0.0     0.0  \n",
       "809806     0.0     0.0     0.0     0.0  \n",
       "\n",
       "[809807 rows x 604705 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1c5ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7b7a0b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming `df` is your pandas dataframe and `clean_text` is the column containing the text data\n",
    "texts = df['clean_text'].tolist()\n",
    "\n",
    "# Build the Word2Vec model\n",
    "model = gensim.models.Word2Vec(vector_size=100, window=5, min_count=1, workers=4)\n",
    "model.build_vocab(texts)\n",
    "\n",
    "# Train the Word2Vec model\n",
    "model.train(texts, total_examples=model.corpus_count, epochs=10)\n",
    "\n",
    "# Encode the text data using the Word2Vec model\n",
    "encoded_texts = []\n",
    "for text in texts:\n",
    "    encoded_text = np.zeros(100)\n",
    "    word_count = 0\n",
    "    for word in text.split():\n",
    "        if word in model.wv.key_to_index:\n",
    "            encoded_text += model.wv[word]\n",
    "            word_count += 1\n",
    "    if word_count > 0:\n",
    "        encoded_text /= word_count\n",
    "    encoded_texts.append(encoded_text)\n",
    "\n",
    "# Create a new pandas dataframe with the encoded text data\n",
    "wordvec_df = pd.DataFrame(encoded_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3a9d0e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809802</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809803</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809804</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809805</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809806</th>\n",
       "      <td>0.691928</td>\n",
       "      <td>-0.807633</td>\n",
       "      <td>-2.479816</td>\n",
       "      <td>1.750501</td>\n",
       "      <td>0.632479</td>\n",
       "      <td>-1.009163</td>\n",
       "      <td>-0.327808</td>\n",
       "      <td>-0.383371</td>\n",
       "      <td>1.740941</td>\n",
       "      <td>-1.139677</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.244033</td>\n",
       "      <td>1.420066</td>\n",
       "      <td>1.023778</td>\n",
       "      <td>0.265729</td>\n",
       "      <td>3.099466</td>\n",
       "      <td>4.373736</td>\n",
       "      <td>-1.494403</td>\n",
       "      <td>-0.840109</td>\n",
       "      <td>-0.146793</td>\n",
       "      <td>0.147354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>809807 rows  100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6   \\\n",
       "0       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "809802  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "809803  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "809804  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "809805  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "809806  0.691928 -0.807633 -2.479816  1.750501  0.632479 -1.009163 -0.327808   \n",
       "\n",
       "              7         8         9   ...        90        91        92  \\\n",
       "0       0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "1       0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "2       0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "3       0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "4       0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "809802  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "809803  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "809804  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "809805  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "809806 -0.383371  1.740941 -1.139677  ... -0.244033  1.420066  1.023778   \n",
       "\n",
       "              93        94        95        96        97        98        99  \n",
       "0       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "809802  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "809803  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "809804  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "809805  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "809806  0.265729  3.099466  4.373736 -1.494403 -0.840109 -0.146793  0.147354  \n",
       "\n",
       "[809807 rows x 100 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordvec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f57fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "09cda4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>00000</th>\n",
       "      <th>0001</th>\n",
       "      <th>0003</th>\n",
       "      <th>00136</th>\n",
       "      <th>002</th>\n",
       "      <th>00409</th>\n",
       "      <th>007</th>\n",
       "      <th>00734</th>\n",
       "      <th>...</th>\n",
       "      <th>kerman</th>\n",
       "      <th>dgar</th>\n",
       "      <th>sta</th>\n",
       "      <th>ste</th>\n",
       "      <th>gaard</th>\n",
       "      <th>ltimo</th>\n",
       "      <th>nica</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80747</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80748</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80749</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80750</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80751</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80752 rows  59946 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        00  000  00000  0001  0003  00136  002  00409  007  00734  ...  \\\n",
       "0      0.0  0.0    0.0   0.0   0.0    0.0  0.0    0.0  0.0    0.0  ...   \n",
       "1      0.0  0.0    0.0   0.0   0.0    0.0  0.0    0.0  0.0    0.0  ...   \n",
       "2      0.0  0.0    0.0   0.0   0.0    0.0  0.0    0.0  0.0    0.0  ...   \n",
       "3      0.0  0.0    0.0   0.0   0.0    0.0  0.0    0.0  0.0    0.0  ...   \n",
       "4      0.0  0.0    0.0   0.0   0.0    0.0  0.0    0.0  0.0    0.0  ...   \n",
       "...    ...  ...    ...   ...   ...    ...  ...    ...  ...    ...  ...   \n",
       "80747  0.0  0.0    0.0   0.0   0.0    0.0  0.0    0.0  0.0    0.0  ...   \n",
       "80748  0.0  0.0    0.0   0.0   0.0    0.0  0.0    0.0  0.0    0.0  ...   \n",
       "80749  0.0  0.0    0.0   0.0   0.0    0.0  0.0    0.0  0.0    0.0  ...   \n",
       "80750  0.0  0.0    0.0   0.0   0.0    0.0  0.0    0.0  0.0    0.0  ...   \n",
       "80751  0.0  0.0    0.0   0.0   0.0    0.0  0.0    0.0  0.0    0.0  ...   \n",
       "\n",
       "       kerman  dgar  sta  ste  gaard  ltimo  nica         \n",
       "0          0.0    0.0   0.0   0.0     0.0     0.0    0.0   0.0  0.0  0.0  \n",
       "1          0.0    0.0   0.0   0.0     0.0     0.0    0.0   0.0  0.0  0.0  \n",
       "2          0.0    0.0   0.0   0.0     0.0     0.0    0.0   0.0  0.0  0.0  \n",
       "3          0.0    0.0   0.0   0.0     0.0     0.0    0.0   0.0  0.0  0.0  \n",
       "4          0.0    0.0   0.0   0.0     0.0     0.0    0.0   0.0  0.0  0.0  \n",
       "...        ...    ...   ...   ...     ...     ...    ...   ...  ...  ...  \n",
       "80747      0.0    0.0   0.0   0.0     0.0     0.0    0.0   0.0  0.0  0.0  \n",
       "80748      0.0    0.0   0.0   0.0     0.0     0.0    0.0   0.0  0.0  0.0  \n",
       "80749      0.0    0.0   0.0   0.0     0.0     0.0    0.0   0.0  0.0  0.0  \n",
       "80750      0.0    0.0   0.0   0.0     0.0     0.0    0.0   0.0  0.0  0.0  \n",
       "80751      0.0    0.0   0.0   0.0     0.0     0.0    0.0   0.0  0.0  0.0  \n",
       "\n",
       "[80752 rows x 59946 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f568e33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2 3 4]\n",
      " [0 1 2 3 4]\n",
      " [0 1 2 3 4]\n",
      " ...\n",
      " [0 1 2 3 4]\n",
      " [1 0 2 3 4]\n",
      " [1 0 2 3 4]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "# Assume X_train, X_test, y_train, y_test are your training and testing features and labels\n",
    "model = SVC(probability=True)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities for each class\n",
    "probs = model.predict_proba(X_test)\n",
    "\n",
    "# Get k classes with highest probabilities for each data point\n",
    "k = 5  # Set k to the desired number of labels\n",
    "predicted_labels = np.argsort(probs, axis=1)[:, -k:]\n",
    "\n",
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d355f574",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "clf = RidgeClassifier(tol=1e-2, solver=\"sparse_cg\")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Get the predicted labels for the test data\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "# Convert the predicted labels to integers\n",
    "pred = pred.astype(int)\n",
    "\n",
    "# Get the number of samples that are predicted to belong to each class\n",
    "class_counts = np.bincount(pred)\n",
    "\n",
    "# Get the indices of the top k classes for each sample\n",
    "top_k_indices = np.argsort(class_counts)[:2]\n",
    "\n",
    "# Get the corresponding labels for the top k classes\n",
    "top_k_labels = np.array([i for i in range(len(class_counts)) if class_counts[i] > 0])[np.flip(top_k_indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "2f163dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.696241718779023\n"
     ]
    }
   ],
   "source": [
    "accuracy = clf.score(X_test, y_test)\n",
    "print(f'Model accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "14fdae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(max_iter=10000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Get the probability estimates for each class\n",
    "proba = clf.predict_proba(X_test)\n",
    "\n",
    "# Get the indices of the top k probabilities for each sample\n",
    "top_k_indices = np.argsort(proba, axis=1)[:, -k:]\n",
    "\n",
    "# Get the corresponding labels for the top k probabilities\n",
    "top_k_labels = np.array([i for i in range(len(class_counts)) if class_counts[i] > 0])[top_k_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "cc392f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4, 5],\n",
       "       [2, 1, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       ...,\n",
       "       [2, 1, 3, 4, 5],\n",
       "       [2, 1, 3, 4, 5],\n",
       "       [2, 3, 1, 4, 5]])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "8b323742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reciprocal_rank(y_true, y_score, k=1):\n",
    "    \"\"\"Calculate the Mean Reciprocal Rank (MRR) for the given true labels and predicted scores.\n",
    "\n",
    "    Parameters:\n",
    "        y_true (array-like): The true labels for the test data.\n",
    "        y_score (array-like): The predicted scores for the test data.\n",
    "        k (int): The number of top predictions to consider.\n",
    "\n",
    "    Returns:\n",
    "        float: The Mean Reciprocal Rank (MRR) for the given true labels and predicted scores.\n",
    "    \"\"\"\n",
    "    ranks = np.zeros(len(y_true))\n",
    "    for i in range(len(y_true)):\n",
    "        scores = y_score[i]\n",
    "        labels = y_true[i]\n",
    "        sorted_indices = np.argsort(-scores)\n",
    "        for j in range(k):\n",
    "            if y_true[sorted_indices[j]] == labels:\n",
    "                ranks[i] = 1 / (j + 1)\n",
    "                break\n",
    "    return np.mean(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "d70c8116",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = preprocess_text_data(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "b0200473",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize a TfidfVectorizer object\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the text data\n",
    "tfidf_data = vectorizer.fit_transform(df['clean_text'])\n",
    "\n",
    "# Create a new dataframe with the TF-IDF encoded data\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Create a sparse dataframe with the TF-IDF encoded data\n",
    "tfidf_df = pd.DataFrame.sparse.from_spmatrix(tfidf_data, columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "c58886bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix, vstack\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define chunk size\n",
    "chunk_size = 1000\n",
    "\n",
    "# Initialize empty sparse matrix\n",
    "X_sparse = coo_matrix((0, tfidf_df.shape[1]))\n",
    "\n",
    "# Convert DataFrame to sparse matrix in chunks\n",
    "for i in range(0, len(tfidf_df), chunk_size):\n",
    "    chunk = tfidf_df.iloc[i:i+chunk_size]\n",
    "    chunk_sparse = coo_matrix(chunk)\n",
    "    X_sparse = vstack([X_sparse, chunk_sparse])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train_sparse, X_test_sparse, y_train, y_test = train_test_split(X_sparse, df[\"rating\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "db6b9b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 0.7024952015355086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split your data into features (X) and target (y)\n",
    "#X = # your TF-IDF encoded data\n",
    "#y = # your target variable\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sparse, df[\"rating\"], test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f'Model accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "af430985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reciprocal Rank (MRR): 0.6747569809918891\n",
      "Mean Average Precision (mAP): 0.9435316685436895\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "k = 2\n",
    "\n",
    "clf = LogisticRegression(max_iter=10000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Get the probability estimates for each class\n",
    "proba = clf.predict_proba(X_test)\n",
    "\n",
    "# Get the indices of the top k probabilities for each sample\n",
    "top_k_indices = np.argsort(proba, axis=1)[:, -k:]\n",
    "\n",
    "# Get the corresponding labels for the top k probabilities\n",
    "top_k_labels = np.array([y_test.iloc[i] for i in top_k_indices.ravel()])\n",
    "\n",
    "# Get the indices of the top k probabilities for each sample in the test data\n",
    "top_k_indices_test = np.searchsorted(np.cumsum(np.bincount(top_k_indices.ravel())), np.arange(len(top_k_indices)))\n",
    "\n",
    "# Get the corresponding scores for the top k probabilities\n",
    "top_k_scores = proba[np.arange(len(y_test))[:, np.newaxis], top_k_indices]\n",
    "\n",
    "# Get the indices of the test data in the original y_test array\n",
    "test_indices = np.searchsorted(np.argsort(y_test), np.arange(len(y_test)))\n",
    "\n",
    "# Calculate the Mean Average Precision (mAP)\n",
    "y_true = top_k_labels[test_indices]\n",
    "y_score = top_k_scores.ravel()[test_indices]\n",
    "map = average_precision_score(y_true, y_score, average='macro', pos_label=max(y_test))\n",
    "\n",
    "# Calculate the Mean Reciprocal Rank (MRR)\n",
    "y_true = y_test.to_numpy()\n",
    "y_score = clf.predict_proba(X_test)\n",
    "mrr = reciprocal_rank(y_true, y_score, k=k)\n",
    "mrr = np.nan_to_num(mrr)\n",
    "\n",
    "print(\"Mean Reciprocal Rank (MRR):\", mrr)\n",
    "\n",
    "print(\"Mean Average Precision (mAP):\", map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6f33b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from data_pipeline import ETL_Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d976de6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "etl = ETL_Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad7c57d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "etl.extract(\"amazon_movie_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33af8f27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "etl.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17900cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "etl.load(\"encoded_review.csv\", create_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c01e093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d74efefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"testing.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "023016ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>007</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>1080p</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>...</th>\n",
       "      <th>younger</th>\n",
       "      <th>youngest</th>\n",
       "      <th>youre</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>youve</th>\n",
       "      <th>yr</th>\n",
       "      <th>zero</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80747</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80748</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80749</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80750</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80751</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80752 rows  5011 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       007   10  100  1000  1080p   11   12   13   14   15  ...  younger  \\\n",
       "0      0.0  0.0  0.0   0.0    0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n",
       "1      0.0  0.0  0.0   0.0    0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n",
       "2      0.0  0.0  0.0   0.0    0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n",
       "3      0.0  0.0  0.0   0.0    0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n",
       "4      0.0  0.0  0.0   0.0    0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n",
       "...    ...  ...  ...   ...    ...  ...  ...  ...  ...  ...  ...      ...   \n",
       "80747  0.0  0.0  0.0   0.0    0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n",
       "80748  0.0  0.0  0.0   0.0    0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n",
       "80749  0.0  0.0  0.0   0.0    0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n",
       "80750  0.0  0.0  0.0   0.0    0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n",
       "80751  0.0  0.0  0.0   0.0    0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   \n",
       "\n",
       "       youngest  youre  youth  youtube  youve   yr  zero  zombie  zone  \n",
       "0           0.0    0.0    0.0      0.0    0.0  0.0   0.0     0.0   0.0  \n",
       "1           0.0    0.0    0.0      0.0    0.0  0.0   0.0     0.0   0.0  \n",
       "2           0.0    0.0    0.0      0.0    0.0  0.0   0.0     0.0   0.0  \n",
       "3           0.0    0.0    0.0      0.0    0.0  0.0   0.0     0.0   0.0  \n",
       "4           0.0    0.0    0.0      0.0    0.0  0.0   0.0     0.0   0.0  \n",
       "...         ...    ...    ...      ...    ...  ...   ...     ...   ...  \n",
       "80747       0.0    0.0    0.0      0.0    0.0  0.0   0.0     0.0   0.0  \n",
       "80748       0.0    0.0    0.0      0.0    0.0  0.0   0.0     0.0   0.0  \n",
       "80749       0.0    0.0    0.0      0.0    0.0  0.0   0.0     0.0   0.0  \n",
       "80750       0.0    0.0    0.0      0.0    0.0  0.0   0.0     0.0   0.0  \n",
       "80751       0.0    0.0    0.0      0.0    0.0  0.0   0.0     0.0   0.0  \n",
       "\n",
       "[80752 rows x 5011 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721aeb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "chunksize = 1000000  # Define the chunk size\n",
    "data_frames = []\n",
    "\n",
    "with open('testing.csv', 'r') as file:\n",
    "    for chunk in pd.read_csv(file, chunksize=chunksize):\n",
    "        data_frames.append(chunk)\n",
    "\n",
    "# Concatenate all the chunks into a single dataframe\n",
    "df = pd.concat(data_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2597c6ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029af616",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "165f4a75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pevah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pevah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\pevah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from model import Movie_Review_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5c9cc51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Movie_Review_Model(\"output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13776082",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      000   10  100   11   12   13   14   15   16   17  ...  wrong  wwii  \\\n",
       " 0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       " 1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       " 2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       " 3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       " 4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       " ...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...   ...   \n",
       " 9995  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       " 9996  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       " 9997  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       " 9998  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       " 9999  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       " \n",
       "       yeah  year  yes  yoga  york  you    young  zombie  \n",
       " 0      0.0   0.0  0.0   0.0   0.0  0.0  0.00000     0.0  \n",
       " 1      0.0   0.0  0.0   0.0   0.0  0.0  0.00000     0.0  \n",
       " 2      0.0   0.0  0.0   0.0   0.0  0.0  0.00000     0.0  \n",
       " 3      0.0   0.0  0.0   0.0   0.0  0.0  0.00000     0.0  \n",
       " 4      0.0   0.0  0.0   0.0   0.0  0.0  0.00000     0.0  \n",
       " ...    ...   ...  ...   ...   ...  ...      ...     ...  \n",
       " 9995   0.0   0.0  0.0   0.0   0.0  0.0  0.12054     0.0  \n",
       " 9996   0.0   0.0  0.0   0.0   0.0  0.0  0.00000     0.0  \n",
       " 9997   0.0   0.0  0.0   0.0   0.0  0.0  0.00000     0.0  \n",
       " 9998   0.0   0.0  0.0   0.0   0.0  0.0  0.00000     0.0  \n",
       " 9999   0.0   0.0  0.0   0.0   0.0  0.0  0.00000     0.0  \n",
       " \n",
       " [10000 rows x 1615 columns],\n",
       " 0       5.0\n",
       " 1       5.0\n",
       " 2       5.0\n",
       " 3       5.0\n",
       " 4       5.0\n",
       "        ... \n",
       " 9995    5.0\n",
       " 9996    5.0\n",
       " 9997    5.0\n",
       " 9998    5.0\n",
       " 9999    5.0\n",
       " Name: rating, Length: 10000, dtype: float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.initiate_etl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4058e248",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082a9b99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save the model to a file\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# load the model from the file\n",
    "with open('model.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2ef1eb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pandas import json_normalize\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea197398",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                   0\n",
      "Unnamed: 0                                                         3\n",
      "review_title                                        2703186189652090\n",
      "text               This movie was alright, would not not recommen...\n",
      "images_x                                             sampleimage.com\n",
      "asin                                                          123214\n",
      "parent_asin                                                 asdf2123\n",
      "user_id                                                        Tyler\n",
      "timestamp                                                     123124\n",
      "helpful_vote                                                      10\n",
      "verified_purchase                                               True\n",
      "main_category                                             a category\n",
      "movie_title                                            Kung Fu Panda\n",
      "subtitle                                              The best movie\n",
      "average_rating                                                      \n",
      "rating_number                                                       \n",
      "features                                          {type: good movie}\n",
      "description                                            Big fat panda\n",
      "price                                                            5.0\n",
      "images_y                            0b242abb623afc578575680df30655b9\n",
      "videos                                                              \n",
      "store                                                    Prime Video\n",
      "categories                                                          \n",
      "details                                                             \n",
      "bought_together                                                   na\n",
      "author                                                    Jack Black\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the JSON file into a dictionary\n",
    "with open('test.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Convert the dictionary into a DataFrame with an index\n",
    "df = pd.DataFrame.from_dict(data, orient='index')\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86eb6bce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = json_normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01194863",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'rating'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'rating'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\John_Hopkins_AI\\creating_ai_enabled_systems\\ai_enabled_system\\modal_movie_review_analyzer\\model.py:110\u001b[0m, in \u001b[0;36mMovie_Review_Model.json_predict\u001b[1;34m(self, info)\u001b[0m\n\u001b[0;32m    108\u001b[0m info\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictions.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39metl\u001b[38;5;241m.\u001b[39mextract(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictions.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 110\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43metl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39metl\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformed_predictions.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    112\u001b[0m info \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformed_predictions.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\John_Hopkins_AI\\creating_ai_enabled_systems\\ai_enabled_system\\modal_movie_review_analyzer\\data_pipeline.py:73\u001b[0m, in \u001b[0;36mETL_Pipeline.transform\u001b[1;34m(self, prediction)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode()\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m prediction:\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mto_export_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrating\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3896\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3898\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'rating'"
     ]
    }
   ],
   "source": [
    "prediction = model.json_predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf6c6cfa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pevah\\AppData\\Local\\Temp\\ipykernel_1312\\2126894162.py:4: DtypeWarning: Columns (25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('small_movie_reviews.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file as a DataFrame\n",
    "df = pd.read_csv('small_movie_reviews.csv')\n",
    "\n",
    "# Create a smaller DataFrame\n",
    "small_df = df.head(10000)  # Take the first 10 rows as an example\n",
    "\n",
    "# Write the smaller DataFrame to a new CSV file\n",
    "small_df.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3901dc30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
